{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff27b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import numpy as np\n",
    "import padre_meddea\n",
    "import pandas as pd\n",
    "import requests\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.table import Table\n",
    "from bs4 import BeautifulSoup\n",
    "from padre_meddea.calibration.calibration import process_file\n",
    "from padre_meddea.io.fits_tools import (  # New Stuff\n",
    "    CUSTOM_ATTRS_PATH,\n",
    ")\n",
    "\n",
    "from solarnet_metadata.schema import SOLARNETSchema\n",
    "from solarnet_metadata.validation import validate_file, validate_header\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95c38dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: UPDATE THIS WITH YOUR OWN LOCAL PATH IF YOU WANT\n",
    "base_path = Path(\"/Users/andrewrobbertz/__SOC_CODE__/_data_/PADRE/MEDDEA\")\n",
    "experiment_path = base_path / \"L1\"\n",
    "\n",
    "if not experiment_path.exists():\n",
    "    os.makedirs(experiment_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99dbf80",
   "metadata": {},
   "source": [
    "## Download the Pipeline-Generated L1 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06437036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_url(base_url, experiment_path, recurse=True, file_extension='.fits'):\n",
    "    \"\"\"\n",
    "    Recursively download files from a URL, preserving directory structure.\n",
    "    \n",
    "    Args:\n",
    "        base_url (str): The URL to download files from\n",
    "        experiment_path (Path): The local path to save files to\n",
    "        recurse (bool): Whether to recursively download from subdirectories\n",
    "        file_extension (str): File extension to filter by (e.g., '.fits')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Accessing {base_url}\")\n",
    "        response = requests.get(base_url)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        \n",
    "        parent_folder = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Create the local directory if it doesn't exist\n",
    "        os.makedirs(experiment_path, exist_ok=True)\n",
    "        \n",
    "        for link in parent_folder.find_all('a'):\n",
    "            href = link.get('href')\n",
    "            \n",
    "            # Skip parent directory links and query parameters\n",
    "            if not href or href.startswith('?') or href.startswith('/') or href == '../':\n",
    "                continue\n",
    "                \n",
    "            # Create full URL for the link\n",
    "            full_url = urljoin(base_url, href)\n",
    "            \n",
    "            # If it's a directory and we're recursing\n",
    "            if href.endswith('/') and recurse:\n",
    "                # Remove trailing slash for local directory name\n",
    "                dir_name = href[:-1]\n",
    "                local_dir = experiment_path / dir_name\n",
    "                \n",
    "                # Recursively download from this directory\n",
    "                download_from_url(full_url, local_dir, recurse, file_extension)\n",
    "            \n",
    "            # If it's a file with the desired extension\n",
    "            elif href.lower().endswith(file_extension.lower()):\n",
    "                print(f\"Downloading {full_url}\")\n",
    "                local_path = experiment_path / href\n",
    "                \n",
    "                # Create parent directories if they don't exist\n",
    "                os.makedirs(local_path.parent, exist_ok=True)\n",
    "                \n",
    "                # Download the file\n",
    "                with open(local_path, 'wb') as file:\n",
    "                    file_response = requests.get(full_url)\n",
    "                    file_response.raise_for_status()\n",
    "                    file.write(file_response.content)\n",
    "                    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error accessing {base_url}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {base_url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8f55609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing https://umbra.nascom.nasa.gov/padre/padre-meddea/l1/\n",
      "Accessing https://umbra.nascom.nasa.gov/padre/padre-meddea/l1/housekeeping/\n",
      "Accessing https://umbra.nascom.nasa.gov/padre/padre-meddea/l1/housekeeping/2025/\n",
      "Accessing https://umbra.nascom.nasa.gov/padre/padre-meddea/l1/housekeeping/2025/05/\n",
      "Accessing https://umbra.nascom.nasa.gov/padre/padre-meddea/l1/housekeeping/2025/05/04/\n",
      "Downloading https://umbra.nascom.nasa.gov/padre/padre-meddea/l1/housekeeping/2025/05/04/padre_meddea_l1_housekeeping_20250504T000000_v0.1.0.fits\n",
      "Accessing https://umbra.nascom.nasa.gov/padre/padre-meddea/l1/spectrum/\n",
      "Accessing https://umbra.nascom.nasa.gov/padre/padre-meddea/l1/spectrum/2025/\n",
      "Accessing https://umbra.nascom.nasa.gov/padre/padre-meddea/l1/spectrum/2025/05/\n",
      "Accessing https://umbra.nascom.nasa.gov/padre/padre-meddea/l1/spectrum/2025/05/04/\n",
      "Downloading https://umbra.nascom.nasa.gov/padre/padre-meddea/l1/spectrum/2025/05/04/padre_meddea_l1_spectrum_20250504T000000_v0.1.0.fits\n"
     ]
    }
   ],
   "source": [
    "### L1 Files\n",
    "base_url = 'https://umbra.nascom.nasa.gov/padre/padre-meddea/l1/'\n",
    "download_from_url(base_url, experiment_path, recurse=True, file_extension='.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77359662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 files in /Users/andrewrobbertz/__SOC_CODE__/_data_/PADRE/MEDDEA/L1\n",
      " - /Users/andrewrobbertz/__SOC_CODE__/_data_/PADRE/MEDDEA/L1/housekeeping/2025/05/04/padre_meddea_l1_housekeeping_20250504T000000_v0.1.0.fits\n",
      " - /Users/andrewrobbertz/__SOC_CODE__/_data_/PADRE/MEDDEA/L1/spectrum/2025/05/04/padre_meddea_l1_spectrum_20250504T000000_v0.1.0.fits\n"
     ]
    }
   ],
   "source": [
    "processed_files = list(experiment_path.rglob('*.fits'))\n",
    "print(f\"Found {len(processed_files)} files in {experiment_path}\")\n",
    "\n",
    "for file in processed_files:\n",
    "    print(f\" - {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02443683",
   "metadata": {},
   "source": [
    "## Check for SOLARNET Compliance in the L1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d08ba53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 15:42:26 - solarnet_metadata.validation - WARNING: Keyword `OBS_HDU` is set to 0, but `is_obs` given as True. Overriding `is_obs` to False. If this is not the desired behavior, please check the header `OBS_HDU`.\n",
      "2025-06-23 15:42:26 - solarnet_metadata.validation - WARNING: Keyword `OBS_HDU` is set to 0, but `is_obs` given as True. Overriding `is_obs` to False. If this is not the desired behavior, please check the header `OBS_HDU`.\n"
     ]
    }
   ],
   "source": [
    "# Create Custome PADRE SOLARNET schema\n",
    "padre_schema = SOLARNETSchema(schema_layers=[CUSTOM_ATTRS_PATH])\n",
    "\n",
    "files = []\n",
    "all_findings = []\n",
    "for processed_file in processed_files:\n",
    "    # Validate the first Processed File against the SOALRNET schema\n",
    "    file_findings = validate_file(\n",
    "        file_path=processed_file,\n",
    "        warn_empty_keyword=True,\n",
    "        warn_no_comment=False,\n",
    "        warn_data_type=True,\n",
    "        schema=padre_schema,\n",
    "    )\n",
    "    all_findings.extend(file_findings)\n",
    "    files.extend([processed_file.name] * len(file_findings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f30e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([files, all_findings]).T\n",
    "df.columns = [\"file\", \"findings\"]\n",
    "\n",
    "# Group by findings and get unique filenames for each finding\n",
    "findings_summary = df.groupby('findings')['file'].unique().reset_index()\n",
    "\n",
    "# Optionally, add a count of files for each finding\n",
    "findings_summary['file_count'] = findings_summary['file'].apply(len)\n",
    "\n",
    "# Sort by most common findings first\n",
    "findings_summary = findings_summary.sort_values('file_count', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "919df57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([\"Observation Header 2: Keyword 'TNULL4' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 2: Keyword 'TNULL6' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 2: Keyword 'TNULL5' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Primary Header: FITS card for 'PARENTXT' exceeds 80 characters (length: 509).\",\n",
      "       \"Observation Header 2: Keyword 'TNULL3' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 2: Keyword 'TNULL2' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 2: Keyword 'JDREF' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 2: Keyword 'TREFPOS' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 2: Keyword 'TUNIT1' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 1: Keyword 'TFIELDS' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Primary Header: FITS card for 'PARENTXT' exceeds 80 characters (length: 169).\",\n",
      "       'Observation Header 2: Missing Required Attribute: CRVALia. No pattern match for CRVALia with pattern CRVAL(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       'Observation Header 2: Missing Required Attribute: CUNITia. No pattern match for CUNITia with pattern CUNIT(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       'Observation Header 2: Missing Required Attribute: XPOSURE',\n",
      "       'Observation Header 2: Missing Required Attribute: CNAMEia. No pattern match for CNAMEia with pattern CNAME(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       'Observation Header 2: Missing Required Attribute: CDELTia. No pattern match for CDELTia with pattern CDELT(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       \"Observation Header 3: Keyword 'GCOUNT' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 3: Keyword 'PCOUNT' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 3: Keyword 'TFIELDS' not found in the schema. Cannot Validate Data Type.\",\n",
      "       'Observation Header 2: Missing Required Attribute: CTYPEia. No pattern match for CTYPEia with pattern CTYPE(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       'Observation Header 2: Missing Required Attribute: CRPIXja. No pattern match for CRPIXja with pattern CRPIX(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       \"Observation Header 1: Keyword 'GCOUNT' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 2: Keyword 'PCOUNT' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 2: Keyword 'GCOUNT' not found in the schema. Cannot Validate Data Type.\",\n",
      "       'Observation Header 1: Missing Required Attribute: XPOSURE',\n",
      "       'Observation Header 1: Missing Required Attribute: CUNITia. No pattern match for CUNITia with pattern CUNIT(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       'Observation Header 1: Missing Required Attribute: CTYPEia. No pattern match for CTYPEia with pattern CTYPE(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       'Observation Header 1: Missing Required Attribute: CRVALia. No pattern match for CRVALia with pattern CRVAL(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       'Observation Header 1: Missing Required Attribute: CRPIXja. No pattern match for CRPIXja with pattern CRPIX(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       'Observation Header 1: Missing Required Attribute: CNAMEia. No pattern match for CNAMEia with pattern CNAME(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       'Observation Header 1: Missing Required Attribute: CDELTia. No pattern match for CDELTia with pattern CDELT(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       \"Observation Header 1: Keyword 'PCOUNT' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 2: Keyword 'TFIELDS' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Primary Header: Keyword 'PARENTXT' not found in the schema. Cannot Validate Data Type.\"],\n",
      "      dtype=object)\n"
     ]
    }
   ],
   "source": [
    "pprint(findings_summary[\"findings\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf827d8",
   "metadata": {},
   "source": [
    "## Explore L1 Concat Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497e945",
   "metadata": {},
   "source": [
    "### Housekeeping Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "600b6037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'padre_meddea_l1_housekeeping_20250504T000000_v0.1.0.fits'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_files[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9f24006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/andrewrobbertz/__SOC_CODE__/_data_/PADRE/MEDDEA/L1/housekeeping/2025/05/04/padre_meddea_l1_housekeeping_20250504T000000_v0.1.0.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU      38   ()      \n",
      "  1  HK            1 BinTableHDU     81   3496R x 16C   [J, I, I, I, I, I, I, I, I, I, I, I, I, I, I, I]   \n",
      "  2  READ          1 BinTableHDU     59   1R x 6C   [2D, J, J, I, I, I]   \n",
      "  3  PROVENANCE    1 BinTableHDU     19   2R x 3C   [60A, 23A, 23A]   \n",
      "None\n",
      "SIMPLE  =                    T / conforms to FITS standard                      \n",
      "BITPIX  =                    8 / array data type                                \n",
      "NAXIS   =                    0 / number of array dimensions                     \n",
      "EXTEND  =                    T                                                  \n",
      "DATE    = '2025-06-23T16:11:30.506' / File creation date in UTC                 \n",
      "AUTHOR  = 'Steven D. Christe'  / Who designed the observation                   \n",
      "CREATOR = 'padre_meddea'       / Name of software pipeline that produced the FIT\n",
      "DATATAGS= '' / Data Tags                                                        \n",
      "DETECTOR= 'meddea  '           / Name of the detector                           \n",
      "INFO_URL= 'https://padre-meddea.readthedocs.io/en/latest/user-guide/data.html' /\n",
      "INSTRUME= 'MeDDEA  '           / Instrument name                                \n",
      "MISSION = 'PADRE   '           / Mission name                                   \n",
      "OBSRVTRY= 'PADRE   '           / Name of the observatory                        \n",
      "ORIGIN  = 'NASA/GSFC'          / File originator                                \n",
      "TELESCOP= 'PADRE/MeDDEA'       / Telescope/Sensor name                          \n",
      "TIMESYS = 'UTC     '           / Time scale of the time-related keywords        \n",
      "BTYPE   = 'housekeeping'       / Data label                                     \n",
      "PRSTEP1 = 'PROCESS Raw to L1'  / Processing step type                           \n",
      "PRPROC1 = 'padre_meddea.calibration.process_file' / Name of procedure performing\n",
      "PRPVER1 = '0.1.dev67+gd204339' / Version of procedure PRPROC1                   \n",
      "PRLIB1A = 'padre_meddea'       / Software library containing PRPROC1            \n",
      "PRVER1A = '0.1.dev67+gd204339' / Version of PRLIB1A                             \n",
      "PRHSH1A = '20b97f9b7c73c4f0a737779975ddc2502178aebd' / GIT commit hash for PRLIB\n",
      "PRLIB1B = 'ccsdspy '                                                            \n",
      "PRVER1B = '1.4.2   '           / Date of last commit of PRLIB1B                 \n",
      "PRHSH1B = 'aafea3f7271b8fc6af9f5990acc04b663a5df6e0'                            \n",
      "PRLIB1C = 'solarnet_metadata'                                                   \n",
      "PRVER1C = '3.0.1.dev40+g063113c'                                                \n",
      "PRHSH1C = '26077b83dab73b76109bd11f87b378ff76302565'                            \n",
      "LEVEL   = 'l1      '           / Data level of fits file                        \n",
      "ORIGAPID=                  163 / APID(s) of the originating data                \n",
      "ORIGFILE= 'PADREMDU8_250504055134.DAT' / Originating file(s)                    \n",
      "DATE-BEG= '2025-05-04T05:51:38.000' / Acquisition start time                    \n",
      "DATEREF = '2025-05-04T05:51:38.000' / Reference date                            \n",
      "FILENAME= '/tmp/padre_meddea_l1_housekeeping_20250504T000000_v0.1.0.fits' / File\n",
      "DATE-END= '2025-05-04T15:34:08.000' / Acquisition end time                      \n",
      "DATE-AVG= '2025-05-04T10:42:53.000' / Average time of acquisition               \n",
      "PARENTXT= 'padre_meddea_l0test_housekeeping_20250504T055138_v0.1.0.fits, &'     \n",
      "CONTINUE  'padre_meddea_l0test_housekeeping_20250504T153118_v0.1.0.fits&'       \n",
      "CONTINUE  '' / Parent files used in concatenation                               \n"
     ]
    }
   ],
   "source": [
    "with fits.open(processed_files[0]) as hdul:\n",
    "    info = hdul.info()\n",
    "    p_hdr = hdul[0].header\n",
    "    # Create Astripy Table from the BinTable HDU with the provenance information\n",
    "    # Assuming the provenance information is in the 4th HDU\n",
    "    provenance = Table(hdul[3].data)\n",
    "pprint(info)\n",
    "pprint(p_hdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a9f368a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=2</i>\n",
       "<table id=\"table5322347856\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>FILENAME</th><th>DATE_BEG</th><th>DATE_END</th></tr></thead>\n",
       "<thead><tr><th>str60</th><th>str23</th><th>str23</th></tr></thead>\n",
       "<tr><td>padre_meddea_l0test_housekeeping_20250504T055138_v0.1.0.fits</td><td>2025-05-04T05:51:38.000</td><td>2025-05-04T05:51:38.000</td></tr>\n",
       "<tr><td>padre_meddea_l0test_housekeeping_20250504T153118_v0.1.0.fits</td><td>2025-05-04T15:31:18.000</td><td>2025-05-04T15:31:18.000</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=2>\n",
       "                          FILENAME                           ...\n",
       "                           str60                             ...\n",
       "------------------------------------------------------------ ...\n",
       "padre_meddea_l0test_housekeeping_20250504T055138_v0.1.0.fits ...\n",
       "padre_meddea_l0test_housekeeping_20250504T153118_v0.1.0.fits ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provenance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e92bb",
   "metadata": {},
   "source": [
    "### Spectrum Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a65d5be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'padre_meddea_l1_spectrum_20250504T000000_v0.1.0.fits'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_files[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "267d2fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/andrewrobbertz/__SOC_CODE__/_data_/PADRE/MEDDEA/L1/spectrum/2025/05/04/padre_meddea_l1_spectrum_20250504T000000_v0.1.0.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU      38   ()      \n",
      "  1  SPEC          1 ImageHDU        30   (512, 24, 2596)   float64   \n",
      "  2  PKT           1 BinTableHDU     49   2596R x 5C   [J, J, 24I, 24I, I]   \n",
      "  3  PROVENANCE    1 BinTableHDU     19   8R x 3C   [56A, 23A, 23A]   \n",
      "None\n",
      "SIMPLE  =                    T / conforms to FITS standard                      \n",
      "BITPIX  =                    8 / array data type                                \n",
      "NAXIS   =                    0 / number of array dimensions                     \n",
      "EXTEND  =                    T                                                  \n",
      "DATE    = '2025-06-23T16:11:39.285' / File creation date in UTC                 \n",
      "AUTHOR  = 'Steven D. Christe'  / Who designed the observation                   \n",
      "CREATOR = 'padre_meddea'       / Name of software pipeline that produced the FIT\n",
      "DATATAGS= '' / Data Tags                                                        \n",
      "DETECTOR= 'meddea  '           / Name of the detector                           \n",
      "INFO_URL= 'https://padre-meddea.readthedocs.io/en/latest/user-guide/data.html' /\n",
      "INSTRUME= 'MeDDEA  '           / Instrument name                                \n",
      "MISSION = 'PADRE   '           / Mission name                                   \n",
      "OBSRVTRY= 'PADRE   '           / Name of the observatory                        \n",
      "ORIGIN  = 'NASA/GSFC'          / File originator                                \n",
      "TELESCOP= 'PADRE/MeDDEA'       / Telescope/Sensor name                          \n",
      "TIMESYS = 'UTC     '           / Time scale of the time-related keywords        \n",
      "BTYPE   = 'spectrum'           / Data label                                     \n",
      "PRSTEP1 = 'PROCESS Raw to L1'  / Processing step type                           \n",
      "PRPROC1 = 'padre_meddea.calibration.process_file' / Name of procedure performing\n",
      "PRPVER1 = '0.1.dev67+gd204339' / Version of procedure PRPROC1                   \n",
      "PRLIB1A = 'padre_meddea'       / Software library containing PRPROC1            \n",
      "PRVER1A = '0.1.dev67+gd204339' / Version of PRLIB1A                             \n",
      "PRHSH1A = '20b97f9b7c73c4f0a737779975ddc2502178aebd' / GIT commit hash for PRLIB\n",
      "PRLIB1B = 'ccsdspy '                                                            \n",
      "PRVER1B = '1.4.2   '           / Date of last commit of PRLIB1B                 \n",
      "PRHSH1B = 'aafea3f7271b8fc6af9f5990acc04b663a5df6e0'                            \n",
      "PRLIB1C = 'solarnet_metadata'                                                   \n",
      "PRVER1C = '3.0.1.dev40+g063113c'                                                \n",
      "PRHSH1C = '26077b83dab73b76109bd11f87b378ff76302565'                            \n",
      "LEVEL   = 'l1      '           / Data level of fits file                        \n",
      "ORIGAPID=                  162 / APID(s) of the originating data                \n",
      "ORIGFILE= 'PADREMDA2_250504070426.DAT' / Originating file(s)                    \n",
      "DATEREF = '2025-05-04T07:04:21.349' / Reference date                            \n",
      "DATE-BEG= '2025-05-04T07:04:21.349' / Acquisition start time                    \n",
      "DATE-END= '2025-05-04T15:33:09.809' / Acquisition end time                      \n",
      "DATE-AVG= '2025-05-04T11:18:45.579' / Average time of acquisition               \n",
      "FILENAME= '/tmp/padre_meddea_l1_spectrum_20250504T000000_v0.1.0.fits' / Filename\n",
      "PARENTXT= 'padre_meddea_l0test_spectrum_20250504T070411_v0.1.0.fits, &'         \n",
      "CONTINUE  'padre_meddea_l0test_spectrum_20250504T081521_v0.1.0.fits, &'         \n",
      "CONTINUE  'padre_meddea_l0test_spectrum_20250504T103811_v0.1.0.fits, &'         \n",
      "CONTINUE  'padre_meddea_l0test_spectrum_20250504T114921_v0.1.0.fits, &'         \n",
      "CONTINUE  'padre_meddea_l0test_spectrum_20250504T130041_v0.1.0.fits, &'         \n",
      "CONTINUE  'padre_meddea_l0test_spectrum_20250504T141211_v0.1.0.fits, &'         \n",
      "CONTINUE  'padre_meddea_l0test_spectrum_20250504T152331_v0.1.0.fits, &'         \n",
      "CONTINUE  'padre_meddea_l0test_spectrum_20250504T153111_v0.1.0.fits&'           \n",
      "CONTINUE  '' / Parent files used in concatenation                               \n"
     ]
    }
   ],
   "source": [
    "with fits.open(processed_files[1]) as hdul:\n",
    "    info = hdul.info()\n",
    "    p_hdr = hdul[0].header\n",
    "    # Create Astripy Table from the BinTable HDU with the provenance information\n",
    "    # Assuming the provenance information is in the 4th HDU\n",
    "    provenance = Table(hdul[3].data)\n",
    "pprint(info)\n",
    "pprint(p_hdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0fba620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=8</i>\n",
       "<table id=\"table5322440784\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>FILENAME</th><th>DATE_BEG</th><th>DATE_END</th></tr></thead>\n",
       "<thead><tr><th>str56</th><th>str23</th><th>str23</th></tr></thead>\n",
       "<tr><td>padre_meddea_l0test_spectrum_20250504T070411_v0.1.0.fits</td><td>2025-05-04T07:04:11.349</td><td>2025-05-04T08:15:11.363</td></tr>\n",
       "<tr><td>padre_meddea_l0test_spectrum_20250504T081521_v0.1.0.fits</td><td>2025-05-04T08:15:21.363</td><td>2025-05-04T09:26:41.378</td></tr>\n",
       "<tr><td>padre_meddea_l0test_spectrum_20250504T103811_v0.1.0.fits</td><td>2025-05-04T10:38:11.392</td><td>2025-05-04T11:49:11.406</td></tr>\n",
       "<tr><td>padre_meddea_l0test_spectrum_20250504T114921_v0.1.0.fits</td><td>2025-05-04T11:49:21.406</td><td>2025-05-04T13:00:31.420</td></tr>\n",
       "<tr><td>padre_meddea_l0test_spectrum_20250504T130041_v0.1.0.fits</td><td>2025-05-04T13:00:41.420</td><td>2025-05-04T14:12:01.433</td></tr>\n",
       "<tr><td>padre_meddea_l0test_spectrum_20250504T141211_v0.1.0.fits</td><td>2025-05-04T14:12:11.433</td><td>2025-05-04T15:23:21.447</td></tr>\n",
       "<tr><td>padre_meddea_l0test_spectrum_20250504T152331_v0.1.0.fits</td><td>2025-05-04T15:23:31.447</td><td>2025-05-04T15:31:01.449</td></tr>\n",
       "<tr><td>padre_meddea_l0test_spectrum_20250504T153111_v0.1.0.fits</td><td>2025-05-04T15:31:11.449</td><td>2025-05-04T15:33:09.809</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=8>\n",
       "                        FILENAME                         ...\n",
       "                         str56                           ...\n",
       "-------------------------------------------------------- ...\n",
       "padre_meddea_l0test_spectrum_20250504T070411_v0.1.0.fits ...\n",
       "padre_meddea_l0test_spectrum_20250504T081521_v0.1.0.fits ...\n",
       "padre_meddea_l0test_spectrum_20250504T103811_v0.1.0.fits ...\n",
       "padre_meddea_l0test_spectrum_20250504T114921_v0.1.0.fits ...\n",
       "padre_meddea_l0test_spectrum_20250504T130041_v0.1.0.fits ...\n",
       "padre_meddea_l0test_spectrum_20250504T141211_v0.1.0.fits ...\n",
       "padre_meddea_l0test_spectrum_20250504T152331_v0.1.0.fits ...\n",
       "padre_meddea_l0test_spectrum_20250504T153111_v0.1.0.fits ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provenance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swxsoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
