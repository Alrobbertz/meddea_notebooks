{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61431332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import padre_meddea\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from padre_meddea import config\n",
    "from padre_meddea.calibration.calibration import process_file\n",
    "from padre_meddea.io.fits_tools import (  # New Stuff\n",
    "    CUSTOM_ATTRS_PATH,\n",
    "    _concatenate_input_files,\n",
    "    _filter_hdul_time_ranges,\n",
    "    _get_combined_list,\n",
    "    _get_output_path,\n",
    "    _init_hdul_structure,\n",
    "    _sort_hdul_template,\n",
    "    _write_output_file,\n",
    "    get_comment,\n",
    "    get_hdu_data_times,\n",
    "    split_hdul_by_day,\n",
    "    split_provenance_tables_by_day,\n",
    "    update_hdul_date_metadata,\n",
    "    update_hdul_filename_metadata,\n",
    ")\n",
    "from padre_meddea.util.util import (\n",
    "    calc_time,\n",
    "    create_science_filename,\n",
    "    parse_science_filename,\n",
    ")\n",
    "from solarnet_metadata.schema import SOLARNETSchema\n",
    "from solarnet_metadata.validation import validate_file, validate_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34651b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_header_times(file_path: Path) -> Tuple[Time, Time]:\n",
    "    \"\"\"\n",
    "    Get the DATE-BEG and DATE-END from the FITS file header.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : Path\n",
    "        Path to the FITS file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[Time, Time]\n",
    "        A tuple containing the start date (DATE-BEG) and end date (DATE-END) as astropy Time objects.\n",
    "\n",
    "    Raises\n",
    "    -------\n",
    "    ValueError\n",
    "        If the file does not contain DATE-BEG, DATE-END, or DATEREF keywords.\n",
    "    \"\"\"\n",
    "    hdul = fits.open(file_path)\n",
    "    header = hdul[0].header.copy()\n",
    "    hdul.close()\n",
    "\n",
    "    # Get Start Date\n",
    "    if \"DATE-BEG\" in header:\n",
    "        date_beg = Time(header[\"DATE-BEG\"])\n",
    "    elif \"DATEREF\" in header:\n",
    "        date_beg = Time(header[\"DATEREF\"])\n",
    "    else:\n",
    "        raise ValueError(f\"File {file_path} does not contain DATE-BEG or DATEREF.\")\n",
    "\n",
    "    # Get End Date\n",
    "    if \"DATE-END\" in header:\n",
    "        date_end = Time(header[\"DATE-END\"])\n",
    "    elif \"DATEREF\" in header:\n",
    "        date_end = Time(header[\"DATEREF\"])\n",
    "    else:\n",
    "        raise ValueError(f\"File {file_path} does not contain DATE-END or DATEREF.\")\n",
    "\n",
    "    return date_beg, date_end\n",
    "\n",
    "\n",
    "def get_file_data_times(file_path: Path) -> Time:\n",
    "    \"\"\"\n",
    "    Extract time information from the data within a FITS file.\n",
    "\n",
    "    This function parses times differently based on the file descriptor (eventlist, hk, spec)\n",
    "    extracted from the filename. It accesses the appropriate HDU and data columns for\n",
    "    each file type to calculate accurate time values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : Path\n",
    "        Path to the FITS file to extract time data from\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Time\n",
    "        Astropy Time object containing the time values extracted from the file data\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the file descriptor is not recognized or supported\n",
    "    \"\"\"\n",
    "    # Get the File Desctiptor\n",
    "    # We need to parse times differently for Photon / Spectrum / HK\n",
    "    file_meta = parse_science_filename(file_path)\n",
    "    file_descriptor = file_meta[\"descriptor\"]\n",
    "    times = None\n",
    "\n",
    "    hdul = fits.open(file_path)\n",
    "    # Calculate Times based on the file descriptor\n",
    "    if file_descriptor == \"photon\":\n",
    "        times = calc_time(\n",
    "            hdul[\"SCI\"].data[\"pkttimes\"],\n",
    "            hdul[\"SCI\"].data[\"pktclock\"],\n",
    "            hdul[\"SCI\"].data[\"clocks\"],\n",
    "        )\n",
    "    elif file_descriptor == \"housekeeping\":\n",
    "        times = calc_time(hdul[\"HK\"].data[\"timestamp\"])\n",
    "    elif file_descriptor == \"spectrum\":\n",
    "        times = calc_time(hdul[\"PKT\"].data[\"pkttimes\"], hdul[\"PKT\"].data[\"pktclock\"])\n",
    "    else:\n",
    "        raise ValueError(f\"File contents of {file_path} not recogized.\")\n",
    "    # Explicitly Open and Close File - Windows Garbage Disposer cannot be trusted.\n",
    "    hdul.close()\n",
    "\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38495b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/padre_meddea/padre_meddea/data/test\n"
     ]
    }
   ],
   "source": [
    "# Get Path to the Unit Test Data Directory\n",
    "test_files_path = Path(padre_meddea.__file__).parent / \"data\" / \"test\"\n",
    "print(test_files_path)\n",
    "test_files_path.exists() or print(\"Test files path does not exist!\")\n",
    "\n",
    "# Make a testfiles path locally if it does not exist\n",
    "cwd = Path.cwd()\n",
    "results_path = cwd / \"testfiles\"\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9c3ae8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instrument</th>\n",
       "      <th>mode</th>\n",
       "      <th>test</th>\n",
       "      <th>time</th>\n",
       "      <th>level</th>\n",
       "      <th>version</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>path</th>\n",
       "      <th>date_beg</th>\n",
       "      <th>date_end</th>\n",
       "      <th>time_beg</th>\n",
       "      <th>time_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meddea</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-05-04T05:51:38.000</td>\n",
       "      <td>l0</td>\n",
       "      <td>0.1.0</td>\n",
       "      <td>housekeeping</td>\n",
       "      <td>/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2025-05-04 05:51:38.000</td>\n",
       "      <td>2025-05-04 05:53:08.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meddea</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-05-04T05:53:08.000</td>\n",
       "      <td>l0</td>\n",
       "      <td>0.1.0</td>\n",
       "      <td>housekeeping</td>\n",
       "      <td>/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2025-05-04 05:53:38.000</td>\n",
       "      <td>2025-05-04 05:55:08.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meddea</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-05-04T05:55:08.000</td>\n",
       "      <td>l0</td>\n",
       "      <td>0.1.0</td>\n",
       "      <td>housekeeping</td>\n",
       "      <td>/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2025-05-04 05:55:38.000</td>\n",
       "      <td>2025-05-04 05:57:08.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meddea</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-05-04T05:57:08.000</td>\n",
       "      <td>l0</td>\n",
       "      <td>0.1.0</td>\n",
       "      <td>housekeeping</td>\n",
       "      <td>/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>2025-05-04 05:57:38.000</td>\n",
       "      <td>2025-05-05 05:59:08.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>meddea</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-05-04T05:53:11.000</td>\n",
       "      <td>l0</td>\n",
       "      <td>0.1.0</td>\n",
       "      <td>photon</td>\n",
       "      <td>/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2025-05-04 05:53:11.353</td>\n",
       "      <td>2025-05-04 05:53:11.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>meddea</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-05-04T07:37:49.000</td>\n",
       "      <td>l0</td>\n",
       "      <td>0.1.0</td>\n",
       "      <td>photon</td>\n",
       "      <td>/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2025-05-04 07:37:49.472</td>\n",
       "      <td>2025-05-04 07:37:49.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meddea</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-05-04T08:03:30.000</td>\n",
       "      <td>l0</td>\n",
       "      <td>0.1.0</td>\n",
       "      <td>photon</td>\n",
       "      <td>/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2025-05-04 08:03:30.385</td>\n",
       "      <td>2025-05-04 08:03:30.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meddea</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-05-04T08:32:34.000</td>\n",
       "      <td>l0</td>\n",
       "      <td>0.1.0</td>\n",
       "      <td>photon</td>\n",
       "      <td>/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>2025-05-04 08:32:34.299</td>\n",
       "      <td>2025-05-05 08:32:34.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meddea</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-05-04T10:38:11.000</td>\n",
       "      <td>l0</td>\n",
       "      <td>0.1.0</td>\n",
       "      <td>spectrum</td>\n",
       "      <td>/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2000-01-01 00:00:00.000</td>\n",
       "      <td>2025-05-04 10:39:51.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>meddea</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-05-04T11:49:21.000</td>\n",
       "      <td>l0</td>\n",
       "      <td>0.1.0</td>\n",
       "      <td>spectrum</td>\n",
       "      <td>/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2000-01-01 00:00:00.000</td>\n",
       "      <td>2025-05-04 11:50:51.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meddea</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-05-04T14:12:11.000</td>\n",
       "      <td>l0</td>\n",
       "      <td>0.1.0</td>\n",
       "      <td>spectrum</td>\n",
       "      <td>/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>2000-01-01 00:00:00.000</td>\n",
       "      <td>2025-05-04 14:13:41.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>meddea</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-05-04T07:04:11.000</td>\n",
       "      <td>l0</td>\n",
       "      <td>0.1.0</td>\n",
       "      <td>spectrum</td>\n",
       "      <td>/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>2000-01-01 00:00:00.000</td>\n",
       "      <td>2025-05-05 07:09:15.748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instrument  mode  test                     time level version  \\\n",
       "1      meddea  None  True  2025-05-04T05:51:38.000    l0   0.1.0   \n",
       "2      meddea  None  True  2025-05-04T05:53:08.000    l0   0.1.0   \n",
       "0      meddea  None  True  2025-05-04T05:55:08.000    l0   0.1.0   \n",
       "3      meddea  None  True  2025-05-04T05:57:08.000    l0   0.1.0   \n",
       "11     meddea  None  True  2025-05-04T05:53:11.000    l0   0.1.0   \n",
       "8      meddea  None  True  2025-05-04T07:37:49.000    l0   0.1.0   \n",
       "10     meddea  None  True  2025-05-04T08:03:30.000    l0   0.1.0   \n",
       "9      meddea  None  True  2025-05-04T08:32:34.000    l0   0.1.0   \n",
       "4      meddea  None  True  2025-05-04T10:38:11.000    l0   0.1.0   \n",
       "5      meddea  None  True  2025-05-04T11:49:21.000    l0   0.1.0   \n",
       "6      meddea  None  True  2025-05-04T14:12:11.000    l0   0.1.0   \n",
       "7      meddea  None  True  2025-05-04T07:04:11.000    l0   0.1.0   \n",
       "\n",
       "      descriptor                                               path  \\\n",
       "1   housekeeping  /Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...   \n",
       "2   housekeeping  /Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...   \n",
       "0   housekeeping  /Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...   \n",
       "3   housekeeping  /Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...   \n",
       "11        photon  /Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...   \n",
       "8         photon  /Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...   \n",
       "10        photon  /Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...   \n",
       "9         photon  /Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...   \n",
       "4       spectrum  /Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...   \n",
       "5       spectrum  /Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...   \n",
       "6       spectrum  /Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...   \n",
       "7       spectrum  /Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/p...   \n",
       "\n",
       "      date_beg    date_end                 time_beg                 time_end  \n",
       "1   2025-05-04  2025-05-04  2025-05-04 05:51:38.000  2025-05-04 05:53:08.000  \n",
       "2   2025-05-04  2025-05-04  2025-05-04 05:53:38.000  2025-05-04 05:55:08.000  \n",
       "0   2025-05-04  2025-05-04  2025-05-04 05:55:38.000  2025-05-04 05:57:08.000  \n",
       "3   2025-05-04  2025-05-05  2025-05-04 05:57:38.000  2025-05-05 05:59:08.000  \n",
       "11  2025-05-04  2025-05-04  2025-05-04 05:53:11.353  2025-05-04 05:53:11.830  \n",
       "8   2025-05-04  2025-05-04  2025-05-04 07:37:49.472  2025-05-04 07:37:49.476  \n",
       "10  2025-05-04  2025-05-04  2025-05-04 08:03:30.385  2025-05-04 08:03:30.390  \n",
       "9   2025-05-04  2025-05-05  2025-05-04 08:32:34.299  2025-05-05 08:32:34.430  \n",
       "4   2000-01-01  2025-05-04  2000-01-01 00:00:00.000  2025-05-04 10:39:51.392  \n",
       "5   2000-01-01  2025-05-04  2000-01-01 00:00:00.000  2025-05-04 11:50:51.406  \n",
       "6   2000-01-01  2025-05-04  2000-01-01 00:00:00.000  2025-05-04 14:13:41.434  \n",
       "7   2000-01-01  2025-05-05  2000-01-01 00:00:00.000  2025-05-05 07:09:15.748  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files = list(test_files_path.rglob(\"*.fits\"))\n",
    "file_meta = []\n",
    "for filename in test_files:\n",
    "\n",
    "    meta = parse_science_filename(filename.name)\n",
    "    meta[\"path\"] = filename.absolute()\n",
    "\n",
    "    # Get the date-beg and date-end from the header\n",
    "    date_beg, date_end = get_file_header_times(filename)\n",
    "    date_beg_iso = date_beg.iso[0:10]  # Convert to ISO format YYYY-MM-DD\n",
    "    date_end_iso = date_end.iso[0:10]  # Convert to ISO format YYYY-MM-DD\n",
    "    meta[\"date_beg\"] = date_beg_iso\n",
    "    meta[\"date_end\"] = date_end_iso\n",
    "\n",
    "    # Get the File Data Times\n",
    "    times: Time = get_file_data_times(filename)\n",
    "    meta[\"time_beg\"] = times[0].iso\n",
    "    meta[\"time_end\"] = times[-1].iso\n",
    "\n",
    "    file_meta.append(meta)\n",
    "\n",
    "df = pd.DataFrame(file_meta)\n",
    "df.sort_values(by=[\"descriptor\", \"time_beg\"], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ecb324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/padre_meddea/padre_meddea/data/test/eventlist/padre_meddea_l0test_photon_20250504T055311_v0.1.0.fits')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0cf377",
   "metadata": {},
   "source": [
    "# Second Table-Based Design\n",
    "\n",
    "-  Possibility that Times will be wrong (i.e. times set to 0 or year 2000) We need to add some sort of check to throw out data from *not this year* Alternatively we can check that there is not too large of a jump in times. \n",
    "- It will probably be on a weekly basis that we'll re-downlink the corrupted files. There will be a person responsible for monitoring the validation outputs and bring these up in the weekly MOC-SOC operational meeting. \n",
    "\n",
    "Pseudocode:\n",
    "1. Create a set of empty data structures or use default data structures from Existing file\n",
    "2. For-Each input File\n",
    "    - 2a Extract the data structures from the input file\n",
    "    - 2b. Concatenate the file data structures into the rolling data structures\n",
    "3. Calculate times for all rolling data structures\n",
    "4. Sort the rolling data structures based on data times\n",
    "     - Will we need to re-calculate the data times? Do we sort with a fancy lambda? Do we do some kind of argsort based on the data times?\n",
    "5. Filter the rolling data structures based on time range checking\n",
    "6. Split the rolling tables based on Day boundaries into separate DOY data structures\n",
    "7. For-each DOY data structure\n",
    "    - 7a. Re-calculate the metadata for each HDU\n",
    "    - 7b. Convert the DOY data structures back into a HDUL\n",
    "    - 7c. Save each HDUL to a unique output file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f37591",
   "metadata": {},
   "source": [
    "## Concat Photon Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94f6b330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/padre_meddea/padre_meddea/data/test/eventlist/padre_meddea_l0test_photon_20250504T055311_v0.1.0.fits'),\n",
       " PosixPath('/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/padre_meddea/padre_meddea/data/test/eventlist/padre_meddea_l0test_photon_20250504T073749_v0.1.0.fits'),\n",
       " PosixPath('/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/padre_meddea/padre_meddea/data/test/eventlist/padre_meddea_l0test_photon_20250504T080330_v0.1.0.fits'),\n",
       " PosixPath('/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/padre_meddea/padre_meddea/data/test/eventlist/padre_meddea_l0test_photon_20250504T083234_v0.1.0.fits')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = list(df[df[\"descriptor\"] == \"photon\"][\"path\"])\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64a40f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-BEG' types <class 'str'> and <class 'str'>, choosing DATE-BEG='2025-05-04T07:37:49.472' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-BEG' types <class 'str'> and <class 'str'>, choosing DATE-BEG='2025-05-04T07:37:49.472'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-04T07:37:49.476' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-04T07:37:49.476'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'ORIGFILE' types <class 'str'> and <class 'str'>, choosing ORIGFILE='PADREMDA0_250504073754.DAT' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'ORIGFILE' types <class 'str'> and <class 'str'>, choosing ORIGFILE='PADREMDA0_250504073754.DAT'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-AVG' types <class 'str'> and <class 'str'>, choosing DATE-AVG='2025-05-04T07:37:49.474' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-AVG' types <class 'str'> and <class 'str'>, choosing DATE-AVG='2025-05-04T07:37:49.474'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:14:20.773' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:14:20.773'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATEREF' types <class 'str'> and <class 'str'>, choosing DATEREF='2025-05-04T07:37:49.472' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATEREF' types <class 'str'> and <class 'str'>, choosing DATEREF='2025-05-04T07:37:49.472'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'FILENAME' types <class 'str'> and <class 'str'>, choosing FILENAME='padre_meddea_l0test_photon_20250504T073749_v0.1.0.fits' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'FILENAME' types <class 'str'> and <class 'str'>, choosing FILENAME='padre_meddea_l0test_photon_20250504T073749_v0.1.0.fits'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='WBMhW9JgWAJgW9Jg' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='WBMhW9JgWAJgW9Jg'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='3817005806' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='3817005806'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:14:20.068' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:14:20.068'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='AW6WDW4WAW4WAW4W' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='AW6WDW4WAW4WAW4W'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='1703896787' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='1703896787'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-BEG' types <class 'str'> and <class 'str'>, choosing DATE-BEG='2025-05-04T08:03:30.385' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-BEG' types <class 'str'> and <class 'str'>, choosing DATE-BEG='2025-05-04T08:03:30.385'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-04T08:03:30.390' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-04T08:03:30.390'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'ORIGFILE' types <class 'str'> and <class 'str'>, choosing ORIGFILE='PADREMDA0_250504080335.DAT' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'ORIGFILE' types <class 'str'> and <class 'str'>, choosing ORIGFILE='PADREMDA0_250504080335.DAT'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-AVG' types <class 'str'> and <class 'str'>, choosing DATE-AVG='2025-05-04T08:03:30.387' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-AVG' types <class 'str'> and <class 'str'>, choosing DATE-AVG='2025-05-04T08:03:30.387'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:14:45.661' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:14:45.661'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATEREF' types <class 'str'> and <class 'str'>, choosing DATEREF='2025-05-04T08:03:30.385' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATEREF' types <class 'str'> and <class 'str'>, choosing DATEREF='2025-05-04T08:03:30.385'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'FILENAME' types <class 'str'> and <class 'str'>, choosing FILENAME='padre_meddea_l0test_photon_20250504T080330_v0.1.0.fits' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'FILENAME' types <class 'str'> and <class 'str'>, choosing FILENAME='padre_meddea_l0test_photon_20250504T080330_v0.1.0.fits'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='IjTWKjQVIjQVIjQV' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='IjTWKjQVIjQVIjQV'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='1049836831' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='1049836831'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:14:45.046' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:14:45.046'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='8qUc8nSZ8nSa8nSY' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='8qUc8nSZ8nSa8nSY'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='624844539' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='624844539'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-BEG' types <class 'str'> and <class 'str'>, choosing DATE-BEG='2025-05-04T08:32:34.299' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-BEG' types <class 'str'> and <class 'str'>, choosing DATE-BEG='2025-05-04T08:32:34.299'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-05T08:32:34.430' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-05T08:32:34.430'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'ORIGFILE' types <class 'str'> and <class 'str'>, choosing ORIGFILE='PADREMDA0_250504083239.DAT' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'ORIGFILE' types <class 'str'> and <class 'str'>, choosing ORIGFILE='PADREMDA0_250504083239.DAT'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-AVG' types <class 'str'> and <class 'str'>, choosing DATE-AVG='2025-05-04T20:32:34.364' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-AVG' types <class 'str'> and <class 'str'>, choosing DATE-AVG='2025-05-04T20:32:34.364'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:14:37.114' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:14:37.114'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATEREF' types <class 'str'> and <class 'str'>, choosing DATEREF='2025-05-04T08:32:34.299' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATEREF' types <class 'str'> and <class 'str'>, choosing DATEREF='2025-05-04T08:32:34.299'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'FILENAME' types <class 'str'> and <class 'str'>, choosing FILENAME='padre_meddea_l0test_photon_20250504T083234_v0.1.0.fits' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'FILENAME' types <class 'str'> and <class 'str'>, choosing FILENAME='padre_meddea_l0test_photon_20250504T083234_v0.1.0.fits'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='1a6C2Y4B1a4B1Y4B' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='1a6C2Y4B1a4B1Y4B'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='1810013585' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='1810013585'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:14:36.445' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:14:36.445'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='3aBT6YAS3aAS3YAS' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='3aBT6YAS3aAS3YAS'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='1432590093' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:12 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='1432590093'\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/swxsoc/lib/python3.12/site-packages/erfa/core.py:133: ErfaWarning: ERFA function \"dtf2d\" yielded 1 of \"dubious year (Note 6)\"\n",
      "  warn(f'ERFA function \"{func_name}\" yielded {wmsg}', ErfaWarning)\n",
      "2025-06-23 14:27:13 - swxsoc - INFO: Created concatenated daily file: padre_meddea_l1_photon_20250504T000000_v0.1.0.fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Created concatenated daily file: padre_meddea_l1_photon_20250504T000000_v0.1.0.fits [padre_meddea.io.fits_tools]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: Card is too long, comment will be truncated. [astropy.io.fits.card]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: VerifyWarning: Card is too long, comment will be truncated.\n",
      "2025-06-23 14:27:13 - swxsoc - INFO: Created concatenated daily file: padre_meddea_l1_photon_20250505T000000_v0.1.0.fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Created concatenated daily file: padre_meddea_l1_photon_20250505T000000_v0.1.0.fits [padre_meddea.io.fits_tools]\n"
     ]
    }
   ],
   "source": [
    "# Change Current Directory to `testfiles`\n",
    "os.chdir(cwd / \"testfiles\")\n",
    "\n",
    "all_files = _get_combined_list(all_files, existing_file=None)\n",
    "\n",
    "# Create new provenance table from the files to combine\n",
    "provenance_tables = split_provenance_tables_by_day(all_files, existing_file=None)\n",
    "\n",
    "# Initialize Data Structures\n",
    "hdul_dict = _init_hdul_structure(all_files[0])\n",
    "\n",
    "# Concatenate Input Files\n",
    "hdul_dict = _concatenate_input_files(all_files[1:], hdul_dict)\n",
    "\n",
    "# Sort Data Structures by Time\n",
    "hdul_dict = _sort_hdul_template(hdul_dict)\n",
    "\n",
    "# Filter HDUL baed on Time Range Checking\n",
    "hdul_dict = _filter_hdul_time_ranges(\n",
    "    hdul_dict=hdul_dict,\n",
    "    start_time=Time(\"2025-01-01 00:00:00.000\", format=\"iso\", scale=\"utc\"),\n",
    "    end_time=Time(\"2050-01-01 00:00:00.000\", format=\"iso\", scale=\"utc\"),\n",
    ")\n",
    "\n",
    "# Split HDU by Day\n",
    "hdul_dicts = split_hdul_by_day(hdul_dict)\n",
    "\n",
    "photon_outfiles = []\n",
    "# Save each Day\n",
    "for day, day_hdul in hdul_dicts.items():\n",
    "\n",
    "    # Calculate the Outputn Path Filename\n",
    "    outfile = _get_output_path(\n",
    "        first_file=all_files[0], date_beg=Time(day + \"T00:00:00\")\n",
    "    )\n",
    "\n",
    "    # Update HDUL Primary Header with Date/Time Information\n",
    "    day_hdul = update_hdul_date_metadata(day_hdul)\n",
    "\n",
    "    # Update HDUL Primary Header with Filename Information\n",
    "    day_hdul = update_hdul_filename_metadata(\n",
    "        day_hdul, outfile, provenance_tables[day]\n",
    "    )\n",
    "\n",
    "    # Add Provenance Table to HDU\n",
    "    if day in provenance_tables:\n",
    "        prov_data = provenance_tables[day]\n",
    "\n",
    "        prov_table = {\n",
    "            \"header\": fits.Header(\n",
    "                [\n",
    "                    (\"EXTNAME\", \"PROVENANCE\", get_comment(\"EXTNAME\")),\n",
    "                    (\"COMMENT\", \"Provenance information for the concatenated files\"),\n",
    "                    (\"OBS_HDU\", 0, get_comment(\"OBS_HDU\")),\n",
    "                ]\n",
    "            ),\n",
    "            \"data\": prov_data,\n",
    "            \"type\": \"bintable\",\n",
    "            \"name\": \"PROVENANCE\",\n",
    "        }\n",
    "        day_hdul[max(day_hdul) + 1] = prov_table\n",
    "\n",
    "    # Write output file\n",
    "    out_path = _write_output_file(day_hdul, outfile)\n",
    "\n",
    "    photon_outfiles.append(Path(out_path))\n",
    "    \n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f254d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('padre_meddea_l1_photon_20250504T000000_v0.1.0.fits'),\n",
       " PosixPath('padre_meddea_l1_photon_20250505T000000_v0.1.0.fits')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photon_outfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e3aa3",
   "metadata": {},
   "source": [
    "## Concat Housekeeping Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d448ce19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/padre_meddea/padre_meddea/data/test/hk/padre_meddea_l0test_housekeeping_20250504T055138_v0.1.0.fits'),\n",
       " PosixPath('/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/padre_meddea/padre_meddea/data/test/hk/padre_meddea_l0test_housekeeping_20250504T055308_v0.1.0.fits'),\n",
       " PosixPath('/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/padre_meddea/padre_meddea/data/test/hk/padre_meddea_l0test_housekeeping_20250504T055508_v0.1.0.fits'),\n",
       " PosixPath('/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/padre_meddea/padre_meddea/data/test/hk/padre_meddea_l0test_housekeeping_20250504T055708_v0.1.0.fits')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = list(df[df[\"descriptor\"] == \"housekeeping\"][\"path\"])\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "803cd6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-BEG' types <class 'str'> and <class 'str'>, choosing DATE-BEG='2025-05-04T05:53:38.000' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-BEG' types <class 'str'> and <class 'str'>, choosing DATE-BEG='2025-05-04T05:53:38.000'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATEREF' types <class 'str'> and <class 'str'>, choosing DATEREF='2025-05-04T05:53:38.000' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATEREF' types <class 'str'> and <class 'str'>, choosing DATEREF='2025-05-04T05:53:38.000'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='XLINYIILXIILXIIL' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='XLINYIILXIILXIIL'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='292204281' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='292204281'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-04T05:55:08.000' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-04T05:55:08.000'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='dOV6fLV3dLV3dLV3' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='dOV6fLV3dLV3dLV3'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-BEG' types <class 'str'> and <class 'str'>, choosing DATE-BEG='2025-05-04T05:55:38.000' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-BEG' types <class 'str'> and <class 'str'>, choosing DATE-BEG='2025-05-04T05:55:38.000'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATEREF' types <class 'str'> and <class 'str'>, choosing DATEREF='2025-05-04T05:55:38.000' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATEREF' types <class 'str'> and <class 'str'>, choosing DATEREF='2025-05-04T05:55:38.000'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='AK5LCJ2IAJ2IAJ2I' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='AK5LCJ2IAJ2IAJ2I'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='331526481' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='331526481'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-04T05:57:08.000' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-04T05:57:08.000'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='dOV3fLV2dLV2dLV2' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='dOV3fLV2dLV2dLV2'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-BEG' types <class 'str'> and <class 'str'>, choosing DATE-BEG='2025-05-04T05:57:38.000' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-BEG' types <class 'str'> and <class 'str'>, choosing DATE-BEG='2025-05-04T05:57:38.000'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATEREF' types <class 'str'> and <class 'str'>, choosing DATEREF='2025-05-04T05:57:38.000' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATEREF' types <class 'str'> and <class 'str'>, choosing DATEREF='2025-05-04T05:57:38.000'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='iLAbkL3biLAbiL3b' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='iLAbkL3biLAbiL3b'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='178083501' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='178083501'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-05T05:59:08.000' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-05T05:59:08.000'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='dNV3fLV0dLV0dLV0' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='dNV3fLV0dLV0dLV0'\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/swxsoc/lib/python3.12/site-packages/erfa/core.py:133: ErfaWarning: ERFA function \"dtf2d\" yielded 1 of \"dubious year (Note 6)\"\n",
      "  warn(f'ERFA function \"{func_name}\" yielded {wmsg}', ErfaWarning)\n",
      "2025-06-23 14:27:13 - swxsoc - INFO: Created concatenated daily file: padre_meddea_l1_housekeeping_20250504T000000_v0.1.0.fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Created concatenated daily file: padre_meddea_l1_housekeeping_20250504T000000_v0.1.0.fits [padre_meddea.io.fits_tools]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: Card is too long, comment will be truncated. [astropy.io.fits.card]\n",
      "2025-06-23 14:27:13 - astropy - WARNING: VerifyWarning: Card is too long, comment will be truncated.\n",
      "2025-06-23 14:27:13 - swxsoc - INFO: Created concatenated daily file: padre_meddea_l1_housekeeping_20250505T000000_v0.1.0.fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Created concatenated daily file: padre_meddea_l1_housekeeping_20250505T000000_v0.1.0.fits [padre_meddea.io.fits_tools]\n"
     ]
    }
   ],
   "source": [
    "# Change Current Directory to `testfiles`\n",
    "os.chdir(cwd / \"testfiles\")\n",
    "\n",
    "all_files = _get_combined_list(all_files, existing_file=None)\n",
    "\n",
    "# Create new provenance table from the files to combine\n",
    "provenance_tables = split_provenance_tables_by_day(all_files, existing_file=None)\n",
    "\n",
    "# Initialize Data Structures\n",
    "hdul_dict = _init_hdul_structure(all_files[0])\n",
    "\n",
    "# Concatenate Input Files\n",
    "hdul_dict = _concatenate_input_files(all_files[1:], hdul_dict)\n",
    "\n",
    "# Sort Data Structures by Time'\n",
    "hdul_dict = _sort_hdul_template(hdul_dict)\n",
    "\n",
    "# Filter HDUL baed on Time Range Checking\n",
    "hdul_dict = _filter_hdul_time_ranges(\n",
    "    hdul_dict=hdul_dict,\n",
    "    start_time=Time(\"2025-01-01 00:00:00.000\", format=\"iso\", scale=\"utc\"),\n",
    "    end_time=Time(\"2050-01-01 00:00:00.000\", format=\"iso\", scale=\"utc\"),\n",
    ")\n",
    "\n",
    "# Split HDU by Day\n",
    "hdul_dicts = split_hdul_by_day(hdul_dict)\n",
    "\n",
    "hk_outfiles = []\n",
    "# Save each Day\n",
    "for day, day_hdul in hdul_dicts.items():\n",
    "\n",
    "    # Calculate the Outputn Path Filename\n",
    "    outfile = _get_output_path(\n",
    "        first_file=all_files[0], date_beg=Time(day + \"T00:00:00\")\n",
    "    )\n",
    "\n",
    "    # Update HDUL Primary Header with Date/Time Information\n",
    "    day_hdul = update_hdul_date_metadata(day_hdul)\n",
    "\n",
    "    # Update HDUL Primary Header with Filename Information\n",
    "    day_hdul = update_hdul_filename_metadata(\n",
    "        day_hdul, outfile, provenance_tables[day]\n",
    "    )\n",
    "\n",
    "    # Add Provenance Table to HDU\n",
    "    if day in provenance_tables:\n",
    "        prov_data = provenance_tables[day]\n",
    "\n",
    "        prov_table = {\n",
    "            \"header\": fits.Header(\n",
    "                [\n",
    "                    (\"EXTNAME\", \"PROVENANCE\", get_comment(\"EXTNAME\")),\n",
    "                    (\"COMMENT\", \"Provenance information for the concatenated files\"),\n",
    "                    (\"OBS_HDU\", 0, get_comment(\"OBS_HDU\")),\n",
    "                ]\n",
    "            ),\n",
    "            \"data\": prov_data,\n",
    "            \"type\": \"bintable\",\n",
    "            \"name\": \"PROVENANCE\",\n",
    "        }\n",
    "        day_hdul[max(day_hdul) + 1] = prov_table\n",
    "\n",
    "    # Write output file\n",
    "    out_path = _write_output_file(day_hdul, outfile)\n",
    "\n",
    "    hk_outfiles.append(Path(out_path))\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d753da5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('padre_meddea_l1_housekeeping_20250504T000000_v0.1.0.fits'),\n",
       " PosixPath('padre_meddea_l1_housekeeping_20250505T000000_v0.1.0.fits')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hk_outfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ebae9e",
   "metadata": {},
   "source": [
    "## Concat Spectrum Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17a83fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/padre_meddea/padre_meddea/data/test/spec/padre_meddea_l0test_spectrum_20250504T103811_v0.1.0.fits'),\n",
       " PosixPath('/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/padre_meddea/padre_meddea/data/test/spec/padre_meddea_l0test_spectrum_20250504T114921_v0.1.0.fits'),\n",
       " PosixPath('/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/padre_meddea/padre_meddea/data/test/spec/padre_meddea_l0test_spectrum_20250504T141211_v0.1.0.fits'),\n",
       " PosixPath('/Users/andrewrobbertz/__SOC_CODE__/PADRE_SOC/padre_meddea/padre_meddea/data/test/spec/padre_meddea_l0test_spectrum_20250504T070411_v0.1.0.fits')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = list(df[df[\"descriptor\"] == \"spectrum\"][\"path\"])\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8981c649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:15:01.735' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:23 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:15:01.735'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'FILENAME' types <class 'str'> and <class 'str'>, choosing FILENAME='padre_meddea_l0test_spectrum_20250504T114921_v0.1.0.fits' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:23 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'FILENAME' types <class 'str'> and <class 'str'>, choosing FILENAME='padre_meddea_l0test_spectrum_20250504T114921_v0.1.0.fits'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='kZg1lZg0kZg0kZg0' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:23 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='kZg1lZg0kZg0kZg0'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='2047846535' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:23 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='2047846535'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-04T11:50:51.406' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:23 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-04T11:50:51.406'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:13:12.448' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:23 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:13:12.448'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'FILENAME' types <class 'str'> and <class 'str'>, choosing FILENAME='padre_meddea_l0test_spectrum_20250504T141211_v0.1.0.fits' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:23 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'FILENAME' types <class 'str'> and <class 'str'>, choosing FILENAME='padre_meddea_l0test_spectrum_20250504T141211_v0.1.0.fits'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='25Ul44Rj24Rj24Rj' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:23 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='25Ul44Rj24Rj24Rj'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='393266032' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:23 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='393266032'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-04T14:13:41.434' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:23 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-04T14:13:41.434'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:14:04.219' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:23 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE' types <class 'str'> and <class 'str'>, choosing DATE='2025-06-17T17:14:04.219'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'FILENAME' types <class 'str'> and <class 'str'>, choosing FILENAME='padre_meddea_l0test_spectrum_20250504T070411_v0.1.0.fits' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:23 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'FILENAME' types <class 'str'> and <class 'str'>, choosing FILENAME='padre_meddea_l0test_spectrum_20250504T070411_v0.1.0.fits'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='3bo93Zl83al83Yl8' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:23 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'CHECKSUM' types <class 'str'> and <class 'str'>, choosing CHECKSUM='3bo93Zl83al83Yl8'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='1727562087' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:23 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATASUM' types <class 'str'> and <class 'str'>, choosing DATASUM='1727562087'\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-05T07:09:15.748' [astropy.utils.metadata.merge]\n",
      "2025-06-23 14:27:23 - astropy - WARNING: MergeConflictWarning: Cannot merge meta key 'DATE-END' types <class 'str'> and <class 'str'>, choosing DATE-END='2025-05-05T07:09:15.748'\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/swxsoc/lib/python3.12/site-packages/erfa/core.py:133: ErfaWarning: ERFA function \"dtf2d\" yielded 1 of \"dubious year (Note 6)\"\n",
      "  warn(f'ERFA function \"{func_name}\" yielded {wmsg}', ErfaWarning)\n",
      "2025-06-23 14:27:23 - swxsoc - INFO: Created concatenated daily file: padre_meddea_l1_spectrum_20250504T000000_v0.1.0.fits\n",
      "WARNING: VerifyWarning: Card is too long, comment will be truncated. [astropy.io.fits.card]\n",
      "2025-06-23 14:27:23 - astropy - WARNING: VerifyWarning: Card is too long, comment will be truncated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Created concatenated daily file: padre_meddea_l1_spectrum_20250504T000000_v0.1.0.fits [padre_meddea.io.fits_tools]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 14:27:23 - swxsoc - INFO: Created concatenated daily file: padre_meddea_l1_spectrum_20250505T000000_v0.1.0.fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Created concatenated daily file: padre_meddea_l1_spectrum_20250505T000000_v0.1.0.fits [padre_meddea.io.fits_tools]\n"
     ]
    }
   ],
   "source": [
    "# Change Current Directory to `testfiles`\n",
    "os.chdir(cwd / \"testfiles\")\n",
    "\n",
    "all_files = _get_combined_list(all_files, existing_file=None)\n",
    "\n",
    "# Create new provenance table from the files to combine\n",
    "provenance_tables = split_provenance_tables_by_day(all_files, existing_file=None)\n",
    "\n",
    "# Initialize Data Structures\n",
    "hdul_dict = _init_hdul_structure(all_files[0])\n",
    "\n",
    "# Concatenate Input Files\n",
    "hdul_dict = _concatenate_input_files(all_files[1:], hdul_dict)\n",
    "\n",
    "# Sort Data Structures by Time'\n",
    "hdul_dict = _sort_hdul_template(hdul_dict)\n",
    "\n",
    "# Filter HDUL baed on Time Range Checking\n",
    "hdul_dict = _filter_hdul_time_ranges(\n",
    "    hdul_dict=hdul_dict,\n",
    "    start_time=Time(\"2025-01-01 00:00:00.000\", format=\"iso\", scale=\"utc\"),\n",
    "    end_time=Time(\"2050-01-01 00:00:00.000\", format=\"iso\", scale=\"utc\"),\n",
    ")\n",
    "\n",
    "# Split HDU by Day\n",
    "hdul_dicts = split_hdul_by_day(hdul_dict)\n",
    "\n",
    "spec_outfiles = []\n",
    "# Save each Day\n",
    "for day, day_hdul in hdul_dicts.items():\n",
    "\n",
    "    # Calculate the Outputn Path Filename\n",
    "    outfile = _get_output_path(\n",
    "        first_file=all_files[0], date_beg=Time(day + \"T00:00:00\")\n",
    "    )\n",
    "\n",
    "    # Update HDUL Primary Header with Date/Time Information\n",
    "    day_hdul = update_hdul_date_metadata(day_hdul)\n",
    "\n",
    "    # Update HDUL Primary Header with Filename Information\n",
    "    day_hdul = update_hdul_filename_metadata(\n",
    "        day_hdul, outfile, provenance_tables[day]\n",
    "    )\n",
    "\n",
    "    # Add Provenance Table to HDU\n",
    "    if day in provenance_tables:\n",
    "        prov_data = provenance_tables[day]\n",
    "\n",
    "        prov_table = {\n",
    "            \"header\": fits.Header(\n",
    "                [\n",
    "                    (\"EXTNAME\", \"PROVENANCE\", get_comment(\"EXTNAME\")),\n",
    "                    (\"COMMENT\", \"Provenance information for the concatenated files\"),\n",
    "                    (\"OBS_HDU\", 0, get_comment(\"OBS_HDU\")),\n",
    "                ]\n",
    "            ),\n",
    "            \"data\": prov_data,\n",
    "            \"type\": \"bintable\",\n",
    "            \"name\": \"PROVENANCE\",\n",
    "        }\n",
    "        day_hdul[max(day_hdul) + 1] = prov_table\n",
    "\n",
    "    # Write output file\n",
    "    out_path = _write_output_file(day_hdul, outfile)\n",
    "\n",
    "    spec_outfiles.append(Path(out_path))\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cd5435c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('padre_meddea_l1_spectrum_20250504T000000_v0.1.0.fits'),\n",
       " PosixPath('padre_meddea_l1_spectrum_20250505T000000_v0.1.0.fits')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_outfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "809604d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: testfiles/padre_meddea_l1_spectrum_20250504T000000_v0.1.0.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU      38   ()      \n",
      "  1  SPEC          1 ImageHDU        31   (512, 24, 31)   float64   \n",
      "  2  PKT           1 BinTableHDU     49   31R x 5C   [J, J, 24I, 24I, I]   \n",
      "  3  PROVENANCE    1 BinTableHDU     19   4R x 3C   [56A, 23A, 23A]   \n",
      "None\n",
      "Filename: testfiles/padre_meddea_l1_spectrum_20250505T000000_v0.1.0.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU      38   ()      \n",
      "  1  SPEC          1 ImageHDU        31   (512, 24, 5)   float64   \n",
      "  2  PKT           1 BinTableHDU     49   5R x 5C   [J, J, 24I, 24I, I]   \n",
      "  3  PROVENANCE    1 BinTableHDU     19   1R x 3C   [56A, 23A, 23A]   \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for file in spec_outfiles:\n",
    "    # Display HDUL Info for each file\n",
    "    hdul = fits.open(\"testfiles\" / file)\n",
    "    pprint(hdul.info())\n",
    "    hdul.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e584ca",
   "metadata": {},
   "source": [
    "## Check for SOLARNET Compliance in the L1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "563f46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfiles = photon_outfiles + hk_outfiles + spec_outfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edb443ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 14:27:24 - solarnet_metadata.validation - WARNING: Keyword `OBS_HDU` is set to 0, but `is_obs` given as True. Overriding `is_obs` to False. If this is not the desired behavior, please check the header `OBS_HDU`.\n",
      "2025-06-23 14:27:24 - solarnet_metadata.validation - WARNING: Keyword `OBS_HDU` is set to 0, but `is_obs` given as True. Overriding `is_obs` to False. If this is not the desired behavior, please check the header `OBS_HDU`.\n",
      "2025-06-23 14:27:24 - solarnet_metadata.validation - WARNING: Keyword `OBS_HDU` is set to 0, but `is_obs` given as True. Overriding `is_obs` to False. If this is not the desired behavior, please check the header `OBS_HDU`.\n",
      "2025-06-23 14:27:24 - solarnet_metadata.validation - WARNING: Keyword `OBS_HDU` is set to 0, but `is_obs` given as True. Overriding `is_obs` to False. If this is not the desired behavior, please check the header `OBS_HDU`.\n",
      "2025-06-23 14:27:24 - solarnet_metadata.validation - WARNING: Keyword `OBS_HDU` is set to 0, but `is_obs` given as True. Overriding `is_obs` to False. If this is not the desired behavior, please check the header `OBS_HDU`.\n",
      "2025-06-23 14:27:24 - solarnet_metadata.validation - WARNING: Keyword `OBS_HDU` is set to 0, but `is_obs` given as True. Overriding `is_obs` to False. If this is not the desired behavior, please check the header `OBS_HDU`.\n"
     ]
    }
   ],
   "source": [
    "# Create Custome PADRE SOLARNET schema\n",
    "padre_schema = SOLARNETSchema(schema_layers=[CUSTOM_ATTRS_PATH])\n",
    "\n",
    "# Change Current Directory to `testfiles`\n",
    "os.chdir(cwd / \"testfiles\")\n",
    "\n",
    "files = []\n",
    "all_findings = []\n",
    "for processed_file in outfiles:\n",
    "    # Validate the first Processed File against the SOALRNET schema\n",
    "    file_findings = validate_file(\n",
    "        file_path=processed_file,\n",
    "        warn_empty_keyword=True,\n",
    "        warn_no_comment=False,\n",
    "        warn_data_type=True,\n",
    "        schema=padre_schema,\n",
    "    )\n",
    "    all_findings.extend(file_findings)\n",
    "    files.extend([processed_file.name] * len(file_findings))\n",
    "    \n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1e50911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>findings</th>\n",
       "      <th>file</th>\n",
       "      <th>file_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Observation Header 2: Value for 'DATE-BEG' can...</td>\n",
       "      <td>[padre_meddea_l1_housekeeping_20250505T000000_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Primary Header: FITS card for 'PARENTXT' excee...</td>\n",
       "      <td>[padre_meddea_l1_spectrum_20250504T000000_v0.1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Primary Header: FITS card for 'PARENTXT' excee...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Primary Header: FITS card for 'PARENTXT' excee...</td>\n",
       "      <td>[padre_meddea_l1_housekeeping_20250504T000000_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Observation Header 2: Value for 'DATEREF' cann...</td>\n",
       "      <td>[padre_meddea_l1_housekeeping_20250505T000000_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Observation Header 2: Value for 'DATE-END' can...</td>\n",
       "      <td>[padre_meddea_l1_housekeeping_20250505T000000_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Observation Header 2: Value for 'DATE-AVG' can...</td>\n",
       "      <td>[padre_meddea_l1_housekeeping_20250505T000000_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Observation Header 2: Keyword 'TUNIT1' not fou...</td>\n",
       "      <td>[padre_meddea_l1_housekeeping_20250504T000000_...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Observation Header 2: Keyword 'TREFPOS' not fo...</td>\n",
       "      <td>[padre_meddea_l1_housekeeping_20250504T000000_...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Observation Header 2: Keyword 'JDREF' not foun...</td>\n",
       "      <td>[padre_meddea_l1_housekeeping_20250504T000000_...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Observation Header 1: Keyword 'TFIELDS' not fo...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Observation Header 2: Missing Required Attribu...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Observation Header 1: Keyword 'GCOUNT' not fou...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Observation Header 2: Missing Required Attribu...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Observation Header 3: Keyword 'GCOUNT' not fou...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Observation Header 3: Keyword 'PCOUNT' not fou...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Observation Header 3: Keyword 'TFIELDS' not fo...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Observation Header 2: Missing Required Attribu...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Observation Header 2: Missing Required Attribu...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Observation Header 2: Missing Required Attribu...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Observation Header 2: Missing Required Attribu...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Observation Header 2: Keyword 'TFIELDS' not fo...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Observation Header 2: Keyword 'PCOUNT' not fou...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Observation Header 2: Keyword 'GCOUNT' not fou...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Observation Header 1: Missing Required Attribu...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Observation Header 1: Missing Required Attribu...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Observation Header 1: Missing Required Attribu...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Observation Header 1: Missing Required Attribu...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Observation Header 1: Missing Required Attribu...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Observation Header 1: Missing Required Attribu...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Observation Header 1: Missing Required Attribu...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Observation Header 1: Keyword 'PCOUNT' not fou...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Observation Header 2: Missing Required Attribu...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Primary Header: Keyword 'PARENTXT' not found i...</td>\n",
       "      <td>[padre_meddea_l1_photon_20250504T000000_v0.1.0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             findings  \\\n",
       "0   Observation Header 2: Value for 'DATE-BEG' can...   \n",
       "1   Primary Header: FITS card for 'PARENTXT' excee...   \n",
       "2   Primary Header: FITS card for 'PARENTXT' excee...   \n",
       "3   Primary Header: FITS card for 'PARENTXT' excee...   \n",
       "4   Observation Header 2: Value for 'DATEREF' cann...   \n",
       "5   Observation Header 2: Value for 'DATE-END' can...   \n",
       "6   Observation Header 2: Value for 'DATE-AVG' can...   \n",
       "7   Observation Header 2: Keyword 'TUNIT1' not fou...   \n",
       "8   Observation Header 2: Keyword 'TREFPOS' not fo...   \n",
       "9   Observation Header 2: Keyword 'JDREF' not foun...   \n",
       "10  Observation Header 1: Keyword 'TFIELDS' not fo...   \n",
       "11  Observation Header 2: Missing Required Attribu...   \n",
       "12  Observation Header 1: Keyword 'GCOUNT' not fou...   \n",
       "13  Observation Header 2: Missing Required Attribu...   \n",
       "14  Observation Header 3: Keyword 'GCOUNT' not fou...   \n",
       "15  Observation Header 3: Keyword 'PCOUNT' not fou...   \n",
       "16  Observation Header 3: Keyword 'TFIELDS' not fo...   \n",
       "17  Observation Header 2: Missing Required Attribu...   \n",
       "18  Observation Header 2: Missing Required Attribu...   \n",
       "19  Observation Header 2: Missing Required Attribu...   \n",
       "20  Observation Header 2: Missing Required Attribu...   \n",
       "21  Observation Header 2: Keyword 'TFIELDS' not fo...   \n",
       "22  Observation Header 2: Keyword 'PCOUNT' not fou...   \n",
       "23  Observation Header 2: Keyword 'GCOUNT' not fou...   \n",
       "24  Observation Header 1: Missing Required Attribu...   \n",
       "25  Observation Header 1: Missing Required Attribu...   \n",
       "26  Observation Header 1: Missing Required Attribu...   \n",
       "27  Observation Header 1: Missing Required Attribu...   \n",
       "28  Observation Header 1: Missing Required Attribu...   \n",
       "29  Observation Header 1: Missing Required Attribu...   \n",
       "30  Observation Header 1: Missing Required Attribu...   \n",
       "31  Observation Header 1: Keyword 'PCOUNT' not fou...   \n",
       "32  Observation Header 2: Missing Required Attribu...   \n",
       "33  Primary Header: Keyword 'PARENTXT' not found i...   \n",
       "\n",
       "                                                 file  file_count  \n",
       "0   [padre_meddea_l1_housekeeping_20250505T000000_...           1  \n",
       "1   [padre_meddea_l1_spectrum_20250504T000000_v0.1...           1  \n",
       "2   [padre_meddea_l1_photon_20250504T000000_v0.1.0...           1  \n",
       "3   [padre_meddea_l1_housekeeping_20250504T000000_...           1  \n",
       "4   [padre_meddea_l1_housekeeping_20250505T000000_...           1  \n",
       "5   [padre_meddea_l1_housekeeping_20250505T000000_...           1  \n",
       "6   [padre_meddea_l1_housekeeping_20250505T000000_...           1  \n",
       "7   [padre_meddea_l1_housekeeping_20250504T000000_...           2  \n",
       "8   [padre_meddea_l1_housekeeping_20250504T000000_...           2  \n",
       "9   [padre_meddea_l1_housekeeping_20250504T000000_...           2  \n",
       "10  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           4  \n",
       "11  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "12  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "13  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "14  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "15  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "16  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "17  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "18  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "19  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "20  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "21  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "22  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "23  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "24  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "25  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "26  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "27  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "28  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "29  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "30  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "31  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "32  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  \n",
       "33  [padre_meddea_l1_photon_20250504T000000_v0.1.0...           6  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([files, all_findings]).T\n",
    "df.columns = [\"file\", \"findings\"]\n",
    "\n",
    "# Group by findings and get unique filenames for each finding\n",
    "findings_summary = df.groupby('findings')['file'].unique().reset_index()\n",
    "\n",
    "# Optionally, add a count of files for each finding\n",
    "findings_summary['file_count'] = findings_summary['file'].apply(len)\n",
    "\n",
    "# Sort by most common findings first\n",
    "findings_summary = findings_summary.sort_values('file_count', ascending=True).reset_index(drop=True)\n",
    "\n",
    "findings_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3101f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([\"Observation Header 2: Value for 'DATE-BEG' cannot be cast to data type 'date': Invalid isoformat string: ''\",\n",
      "       \"Primary Header: FITS card for 'PARENTXT' exceeds 80 characters (length: 277).\",\n",
      "       \"Primary Header: FITS card for 'PARENTXT' exceeds 80 characters (length: 269).\",\n",
      "       \"Primary Header: FITS card for 'PARENTXT' exceeds 80 characters (length: 293).\",\n",
      "       \"Observation Header 2: Value for 'DATEREF' cannot be cast to data type 'date': Invalid isoformat string: ''\",\n",
      "       \"Observation Header 2: Value for 'DATE-END' cannot be cast to data type 'date': Invalid isoformat string: ''\",\n",
      "       \"Observation Header 2: Value for 'DATE-AVG' cannot be cast to data type 'date': Invalid isoformat string: ''\",\n",
      "       \"Observation Header 2: Keyword 'TUNIT1' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 2: Keyword 'TREFPOS' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 2: Keyword 'JDREF' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 1: Keyword 'TFIELDS' not found in the schema. Cannot Validate Data Type.\",\n",
      "       'Observation Header 2: Missing Required Attribute: CUNITia. No pattern match for CUNITia with pattern CUNIT(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       \"Observation Header 1: Keyword 'GCOUNT' not found in the schema. Cannot Validate Data Type.\",\n",
      "       'Observation Header 2: Missing Required Attribute: CTYPEia. No pattern match for CTYPEia with pattern CTYPE(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       \"Observation Header 3: Keyword 'GCOUNT' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 3: Keyword 'PCOUNT' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 3: Keyword 'TFIELDS' not found in the schema. Cannot Validate Data Type.\",\n",
      "       'Observation Header 2: Missing Required Attribute: XPOSURE',\n",
      "       'Observation Header 2: Missing Required Attribute: CRVALia. No pattern match for CRVALia with pattern CRVAL(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       'Observation Header 2: Missing Required Attribute: CDELTia. No pattern match for CDELTia with pattern CDELT(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       'Observation Header 2: Missing Required Attribute: CNAMEia. No pattern match for CNAMEia with pattern CNAME(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       \"Observation Header 2: Keyword 'TFIELDS' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 2: Keyword 'PCOUNT' not found in the schema. Cannot Validate Data Type.\",\n",
      "       \"Observation Header 2: Keyword 'GCOUNT' not found in the schema. Cannot Validate Data Type.\",\n",
      "       'Observation Header 1: Missing Required Attribute: XPOSURE',\n",
      "       'Observation Header 1: Missing Required Attribute: CUNITia. No pattern match for CUNITia with pattern CUNIT(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       'Observation Header 1: Missing Required Attribute: CTYPEia. No pattern match for CTYPEia with pattern CTYPE(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       'Observation Header 1: Missing Required Attribute: CRVALia. No pattern match for CRVALia with pattern CRVAL(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       'Observation Header 1: Missing Required Attribute: CRPIXja. No pattern match for CRPIXja with pattern CRPIX(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       'Observation Header 1: Missing Required Attribute: CNAMEia. No pattern match for CNAMEia with pattern CNAME(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       'Observation Header 1: Missing Required Attribute: CDELTia. No pattern match for CDELTia with pattern CDELT(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       \"Observation Header 1: Keyword 'PCOUNT' not found in the schema. Cannot Validate Data Type.\",\n",
      "       'Observation Header 2: Missing Required Attribute: CRPIXja. No pattern match for CRPIXja with pattern CRPIX(?P<i>[1-9])(?P<a>[A-Z])?',\n",
      "       \"Primary Header: Keyword 'PARENTXT' not found in the schema. Cannot Validate Data Type.\"],\n",
      "      dtype=object)\n"
     ]
    }
   ],
   "source": [
    "pprint(findings_summary[\"findings\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a160e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swxsoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
